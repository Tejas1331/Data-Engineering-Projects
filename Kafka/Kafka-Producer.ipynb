{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0fa2499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import threading\n",
    "from decimal import *\n",
    "from time import sleep\n",
    "from uuid import uuid4, UUID\n",
    "\n",
    "from confluent_kafka import SerializingProducer\n",
    "from confluent_kafka.schema_registry import SchemaRegistryClient\n",
    "from confluent_kafka.schema_registry.avro import AvroSerializer\n",
    "from confluent_kafka.serialization import StringSerializer\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "819da5fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "SchemaRegistryError",
     "evalue": "Unauthorized (HTTP status code 401, SR code 401)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSchemaRegistryError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 55>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Fetch the latest Avro schema for the value\u001b[39;00m\n\u001b[0;32m     54\u001b[0m subject_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretail_data-value\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 55\u001b[0m schema_str \u001b[38;5;241m=\u001b[39m \u001b[43mschema_registry_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_latest_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject_name\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mschema\u001b[38;5;241m.\u001b[39mschema_str\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28mprint\u001b[39m(schema_str)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Create Avro Serializer for the value\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# key_serializer = AvroSerializer(schema_registry_client=schema_registry_client, schema_str='{\"type\": \"string\"}')\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\confluent_kafka\\schema_registry\\schema_registry_client.py:491\u001b[0m, in \u001b[0;36mSchemaRegistryClient.get_latest_version\u001b[1;34m(self, subject_name)\u001b[0m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_latest_version\u001b[39m(\u001b[38;5;28mself\u001b[39m, subject_name):\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;124;03m    Retrieves latest registered version for subject\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;124;03m        `GET Subject Version API Reference <https://docs.confluent.io/current/schema-registry/develop/api.html#get--subjects-(string-%20subject)-versions-(versionId-%20version)>`_\u001b[39;00m\n\u001b[0;32m    489\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[1;32m--> 491\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rest_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msubjects/\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m/versions/\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m    492\u001b[0m \u001b[43m                                     \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_urlencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m                                             \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlatest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    495\u001b[0m     schema_type \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mschemaType\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAVRO\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    496\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m RegisteredSchema(schema_id\u001b[38;5;241m=\u001b[39mresponse[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    497\u001b[0m                             schema\u001b[38;5;241m=\u001b[39mSchema(response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mschema\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    498\u001b[0m                                           schema_type,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    505\u001b[0m                             subject\u001b[38;5;241m=\u001b[39mresponse[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubject\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    506\u001b[0m                             version\u001b[38;5;241m=\u001b[39mresponse[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\confluent_kafka\\schema_registry\\schema_registry_client.py:125\u001b[0m, in \u001b[0;36m_RestClient.get\u001b[1;34m(self, url, query)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url, query\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\confluent_kafka\\schema_registry\\schema_registry_client.py:175\u001b[0m, in \u001b[0;36m_RestClient.send_request\u001b[1;34m(self, url, method, body, query)\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m299\u001b[39m:\n\u001b[0;32m    174\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m--> 175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SchemaRegistryError(response\u001b[38;5;241m.\u001b[39mstatus_code,\n\u001b[0;32m    176\u001b[0m                               response\u001b[38;5;241m.\u001b[39mjson()\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror_code\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m    177\u001b[0m                               response\u001b[38;5;241m.\u001b[39mjson()\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m    178\u001b[0m \u001b[38;5;66;03m# Schema Registry may return malformed output when it hits unexpected errors\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mKeyError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m):\n",
      "\u001b[1;31mSchemaRegistryError\u001b[0m: Unauthorized (HTTP status code 401, SR code 401)"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import threading\n",
    "from decimal import *\n",
    "from time import sleep\n",
    "from uuid import uuid4, UUID\n",
    "\n",
    "from confluent_kafka import SerializingProducer\n",
    "from confluent_kafka.schema_registry import SchemaRegistryClient\n",
    "from confluent_kafka.schema_registry.avro import AvroSerializer\n",
    "from confluent_kafka.serialization import StringSerializer\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def delivery_report(err, msg):\n",
    "    \"\"\"\n",
    "    Reports the failure or success of a message delivery.\n",
    "\n",
    "    Args:\n",
    "        err (KafkaError): The error that occurred on None on success.\n",
    "\n",
    "        msg (Message): The message that was produced or failed.\n",
    "\n",
    "    Note:\n",
    "        In the delivery report callback the Message.key() and Message.value()\n",
    "        will be the binary format as encoded by any configured Serializers and\n",
    "        not the same object that was passed to produce().\n",
    "        If you wish to pass the original object(s) for key and value to delivery\n",
    "        report callback we recommend a bound callback or lambda where you pass\n",
    "        the objects along.\n",
    "\n",
    "    \"\"\"\n",
    "    if err is not None:\n",
    "        print(\"Delivery failed for User record {}: {}\".format(msg.key(), err))\n",
    "        return\n",
    "    print('User record {} successfully produced to {} [{}] at offset {}'.format(\n",
    "        msg.key(), msg.topic(), msg.partition(), msg.offset()))\n",
    "\n",
    "# Define Kafka configuration\n",
    "kafka_config = {\n",
    "    'bootstrap.servers': 'pkc-41p56.asia-south1.gcp.confluent.cloud:9092',\n",
    "    'sasl.mechanisms': 'PLAIN',\n",
    "    'security.protocol': 'SASL_SSL',\n",
    "    'sasl.username': 'LSFOPOKCFIB5IRYC',\n",
    "    'sasl.password': 'ZHbZky1eKCv7m+941Z03iina4sElhd3q4s7SAzfFLHkJIjUGV77onKTHxWeQUb+D'\n",
    "}\n",
    "\n",
    "# Create a Schema Registry client\n",
    "schema_registry_client = SchemaRegistryClient({\n",
    "  'url': 'https://psrc-l622j.us-east-2.aws.confluent.cloud',\n",
    "  'basic.auth.user.info': '{}:{}'.format('GOM2TBQNOLFB4GR4', 'G0ovcSrTMBaJsOkLVamLF0SwhHYZd9Z9YRWHzuJ5CJig25SerulEOZt+AVE6oCOi')\n",
    "})\n",
    "\n",
    "# Fetch the latest Avro schema for the value\n",
    "subject_name = 'retail_data-value'\n",
    "schema_str = schema_registry_client.get_latest_version(subject_name).schema.schema_str\n",
    "print(schema_str)\n",
    "\n",
    "# Create Avro Serializer for the value\n",
    "# key_serializer = AvroSerializer(schema_registry_client=schema_registry_client, schema_str='{\"type\": \"string\"}')\n",
    "key_serializer = StringSerializer('utf_8')\n",
    "avro_serializer = AvroSerializer(schema_registry_client, schema_str)\n",
    "\n",
    "# Define the SerializingProducer\n",
    "producer = SerializingProducer({\n",
    "    'bootstrap.servers': kafka_config['bootstrap.servers'],\n",
    "    'security.protocol': kafka_config['security.protocol'],\n",
    "    'sasl.mechanisms': kafka_config['sasl.mechanisms'],\n",
    "    'sasl.username': kafka_config['sasl.username'],\n",
    "    'sasl.password': kafka_config['sasl.password'],\n",
    "    'key.serializer': key_serializer,  # Key will be serialized as a string\n",
    "    'value.serializer': avro_serializer  # Value will be serialized as Avro\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "# Load the CSV data into a pandas DataFrame\n",
    "df = pd.read_csv('retail_data.csv')\n",
    "df = df.fillna('null')\n",
    "\n",
    "# Iterate over DataFrame rows and produce to Kafka\n",
    "for index, row in df.iterrows():\n",
    "    # Create a dictionary from the row values\n",
    "    value = row.to_dict()\n",
    "    # Produce to Kafka\n",
    "    producer.produce(topic='retail_data', key=str(index), value=value, on_delivery=delivery_report)\n",
    "    producer.flush()\n",
    "    break\n",
    "\n",
    "print(\"Data successfully published to Kafka\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cd13c39",
   "metadata": {},
   "outputs": [
    {
     "ename": "SchemaRegistryError",
     "evalue": "Unauthorized (HTTP status code 401, SR code 401)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSchemaRegistryError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 55>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Fetch the latest Avro schema for the value\u001b[39;00m\n\u001b[0;32m     54\u001b[0m subject_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretail_data-value\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 55\u001b[0m schema_str \u001b[38;5;241m=\u001b[39m \u001b[43mschema_registry_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_latest_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject_name\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mschema\u001b[38;5;241m.\u001b[39mschema_str\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28mprint\u001b[39m(schema_str)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Create Avro Serializer for the value\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# key_serializer = AvroSerializer(schema_registry_client=schema_registry_client, schema_str='{\"type\": \"string\"}')\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\confluent_kafka\\schema_registry\\schema_registry_client.py:491\u001b[0m, in \u001b[0;36mSchemaRegistryClient.get_latest_version\u001b[1;34m(self, subject_name)\u001b[0m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_latest_version\u001b[39m(\u001b[38;5;28mself\u001b[39m, subject_name):\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;124;03m    Retrieves latest registered version for subject\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;124;03m        `GET Subject Version API Reference <https://docs.confluent.io/current/schema-registry/develop/api.html#get--subjects-(string-%20subject)-versions-(versionId-%20version)>`_\u001b[39;00m\n\u001b[0;32m    489\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[1;32m--> 491\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rest_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msubjects/\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m/versions/\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m    492\u001b[0m \u001b[43m                                     \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_urlencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m                                             \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlatest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    495\u001b[0m     schema_type \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mschemaType\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAVRO\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    496\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m RegisteredSchema(schema_id\u001b[38;5;241m=\u001b[39mresponse[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    497\u001b[0m                             schema\u001b[38;5;241m=\u001b[39mSchema(response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mschema\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    498\u001b[0m                                           schema_type,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    505\u001b[0m                             subject\u001b[38;5;241m=\u001b[39mresponse[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubject\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    506\u001b[0m                             version\u001b[38;5;241m=\u001b[39mresponse[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\confluent_kafka\\schema_registry\\schema_registry_client.py:125\u001b[0m, in \u001b[0;36m_RestClient.get\u001b[1;34m(self, url, query)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url, query\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\confluent_kafka\\schema_registry\\schema_registry_client.py:175\u001b[0m, in \u001b[0;36m_RestClient.send_request\u001b[1;34m(self, url, method, body, query)\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m299\u001b[39m:\n\u001b[0;32m    174\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m--> 175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SchemaRegistryError(response\u001b[38;5;241m.\u001b[39mstatus_code,\n\u001b[0;32m    176\u001b[0m                               response\u001b[38;5;241m.\u001b[39mjson()\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror_code\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m    177\u001b[0m                               response\u001b[38;5;241m.\u001b[39mjson()\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m    178\u001b[0m \u001b[38;5;66;03m# Schema Registry may return malformed output when it hits unexpected errors\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mKeyError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m):\n",
      "\u001b[1;31mSchemaRegistryError\u001b[0m: Unauthorized (HTTP status code 401, SR code 401)"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import threading\n",
    "from decimal import *\n",
    "from time import sleep\n",
    "from uuid import uuid4, UUID\n",
    "\n",
    "from confluent_kafka import SerializingProducer\n",
    "from confluent_kafka.schema_registry import SchemaRegistryClient\n",
    "from confluent_kafka.schema_registry.avro import AvroSerializer\n",
    "from confluent_kafka.serialization import StringSerializer\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def delivery_report(err, msg):\n",
    "    \"\"\"\n",
    "    Reports the failure or success of a message delivery.\n",
    "\n",
    "    Args:\n",
    "        err (KafkaError): The error that occurred on None on success.\n",
    "\n",
    "        msg (Message): The message that was produced or failed.\n",
    "\n",
    "    Note:\n",
    "        In the delivery report callback the Message.key() and Message.value()\n",
    "        will be the binary format as encoded by any configured Serializers and\n",
    "        not the same object that was passed to produce().\n",
    "        If you wish to pass the original object(s) for key and value to delivery\n",
    "        report callback we recommend a bound callback or lambda where you pass\n",
    "        the objects along.\n",
    "\n",
    "    \"\"\"\n",
    "    if err is not None:\n",
    "        print(\"Delivery failed for User record {}: {}\".format(msg.key(), err))\n",
    "        return\n",
    "    print('User record {} successfully produced to {} [{}] at offset {}'.format(\n",
    "        msg.key(), msg.topic(), msg.partition(), msg.offset()))\n",
    "\n",
    "# Define Kafka configuration\n",
    "kafka_config = {\n",
    "    'bootstrap.servers': 'pkc-41p56.asia-south1.gcp.confluent.cloud:9092',\n",
    "    'sasl.mechanisms': 'PLAIN',\n",
    "    'security.protocol': 'SASL_SSL',\n",
    "    'sasl.username': 'AJWNXLM2LQIZQIS4',\n",
    "    'sasl.password': '7K56fo+AuH5GBM5JztKj5CUOpu9eFTOxiNloKzuEpGRFP8NhTBxn86/6io8T6IS6'\n",
    "}\n",
    "\n",
    "# Create a Schema Registry client\n",
    "schema_registry_client = SchemaRegistryClient({\n",
    "  'url': 'https://psrc-l622j.us-east-2.aws.confluent.cloud',\n",
    "  'basic.auth.user.info': '{}:{}'.format('K3P7ECU2CV537I2I', 'XH569MPA/z7egxheneylyDQnyGVeF/2PXbNz9F/gVSpZ8eZpVieryrf1YETfATO/')\n",
    "})\n",
    "\n",
    "# Fetch the latest Avro schema for the value\n",
    "subject_name = 'retail_data-value'\n",
    "schema_str = schema_registry_client.get_latest_version(subject_name).schema.schema_str\n",
    "print(schema_str)\n",
    "\n",
    "# Create Avro Serializer for the value\n",
    "# key_serializer = AvroSerializer(schema_registry_client=schema_registry_client, schema_str='{\"type\": \"string\"}')\n",
    "key_serializer = StringSerializer('utf_8')\n",
    "avro_serializer = AvroSerializer(schema_registry_client, schema_str)\n",
    "\n",
    "# Define the SerializingProducer\n",
    "producer = SerializingProducer({\n",
    "    'bootstrap.servers': kafka_config['bootstrap.servers'],\n",
    "    'security.protocol': kafka_config['security.protocol'],\n",
    "    'sasl.mechanisms': kafka_config['sasl.mechanisms'],\n",
    "    'sasl.username': kafka_config['sasl.username'],\n",
    "    'sasl.password': kafka_config['sasl.password'],\n",
    "    'key.serializer': key_serializer,  # Key will be serialized as a string\n",
    "    'value.serializer': avro_serializer  # Value will be serialized as Avro\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "# Load the CSV data into a pandas DataFrame\n",
    "df = pd.read_csv('retail_data.csv')\n",
    "df = df.fillna('null')\n",
    "\n",
    "# Iterate over DataFrame rows and produce to Kafka\n",
    "for index, row in df.iterrows():\n",
    "    # Create a dictionary from the row values\n",
    "    value = row.to_dict()\n",
    "    # Produce to Kafka\n",
    "    producer.produce(topic='retail_data', key=str(index), value=value, on_delivery=delivery_report)\n",
    "    producer.flush()\n",
    "    break\n",
    "\n",
    "print(\"Data successfully published to Kafka\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5399b56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
